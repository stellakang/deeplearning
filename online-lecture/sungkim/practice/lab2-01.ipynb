{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(777) #for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Y data\n",
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable은 tensorflow가 학습시키는 과정에서 값을 바꾼다.(trainable)\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our hypothesis Wx+b\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.5240757 [2.1286771] [-0.8523567]\n",
      "20 0.19749945 [1.533928] [-1.0505961]\n",
      "40 0.15214379 [1.4572546] [-1.0239124]\n",
      "60 0.13793248 [1.4308538] [-0.9779527]\n",
      "80 0.12527026 [1.4101374] [-0.93219817]\n",
      "100 0.11377231 [1.3908179] [-0.8884077]\n",
      "120 0.10332986 [1.3724468] [-0.8466577]\n",
      "140 0.09384582 [1.3549428] [-0.80686814]\n",
      "160 0.08523231 [1.3382617] [-0.7689483]\n",
      "180 0.077409334 [1.3223647] [-0.7328106]\n",
      "200 0.07030442 [1.3072149] [-0.69837123]\n",
      "220 0.06385163 [1.2927768] [-0.66555053]\n",
      "240 0.05799109 [1.2790174] [-0.6342722]\n",
      "260 0.052668452 [1.2659047] [-0.6044637]\n",
      "280 0.047834326 [1.2534082] [-0.57605624]\n",
      "300 0.04344389 [1.2414987] [-0.5489837]\n",
      "320 0.03945643 [1.2301493] [-0.52318335]\n",
      "340 0.035834953 [1.2193329] [-0.49859563]\n",
      "360 0.032545887 [1.2090253] [-0.47516343]\n",
      "380 0.029558683 [1.1992017] [-0.45283243]\n",
      "400 0.026845647 [1.18984] [-0.43155095]\n",
      "420 0.024381677 [1.1809182] [-0.4112697]\n",
      "440 0.022143835 [1.1724157] [-0.39194155]\n",
      "460 0.020111376 [1.164313] [-0.3735217]\n",
      "480 0.01826544 [1.1565907] [-0.35596746]\n",
      "500 0.016588978 [1.1492316] [-0.3392383]\n",
      "520 0.015066381 [1.1422179] [-0.32329533]\n",
      "540 0.013683519 [1.1355344] [-0.30810153]\n",
      "560 0.012427575 [1.1291647] [-0.29362193]\n",
      "580 0.011286947 [1.1230947] [-0.27982277]\n",
      "600 0.010250964 [1.1173096] [-0.2666721]\n",
      "620 0.009310109 [1.1117965] [-0.25413954]\n",
      "640 0.008455591 [1.1065423] [-0.24219596]\n",
      "660 0.007679501 [1.1015354] [-0.23081371]\n",
      "680 0.006974652 [1.0967636] [-0.21996634]\n",
      "700 0.006334486 [1.092216] [-0.20962876]\n",
      "720 0.0057530873 [1.0878823] [-0.19977696]\n",
      "740 0.005225048 [1.0837523] [-0.19038828]\n",
      "760 0.0047454657 [1.079816] [-0.18144065]\n",
      "780 0.004309909 [1.076065] [-0.17291357]\n",
      "800 0.003914328 [1.0724903] [-0.1647873]\n",
      "820 0.003555062 [1.0690836] [-0.15704301]\n",
      "840 0.0032287624 [1.0658369] [-0.14966261]\n",
      "860 0.0029324212 [1.0627428] [-0.14262903]\n",
      "880 0.002663277 [1.0597941] [-0.13592613]\n",
      "900 0.0024188298 [1.056984] [-0.12953807]\n",
      "920 0.002196817 [1.0543059] [-0.12345023]\n",
      "940 0.0019951796 [1.0517538] [-0.11764851]\n",
      "960 0.0018120552 [1.0493215] [-0.11211942]\n",
      "980 0.0016457397 [1.0470036] [-0.10685021]\n",
      "1000 0.0014946844 [1.0447947] [-0.10182866]\n",
      "1020 0.001357506 [1.0426896] [-0.09704316]\n",
      "1040 0.0012329047 [1.0406834] [-0.09248255]\n",
      "1060 0.0011197398 [1.0387712] [-0.08813614]\n",
      "1080 0.0010169642 [1.0369492] [-0.08399406]\n",
      "1100 0.0009236282 [1.0352126] [-0.08004666]\n",
      "1120 0.000838855 [1.0335578] [-0.07628474]\n",
      "1140 0.000761858 [1.0319808] [-0.07269964]\n",
      "1160 0.00069193525 [1.0304776] [-0.06928304]\n",
      "1180 0.0006284237 [1.0290452] [-0.06602691]\n",
      "1200 0.0005707424 [1.0276803] [-0.06292386]\n",
      "1220 0.0005183569 [1.0263795] [-0.05996668]\n",
      "1240 0.0004707781 [1.0251397] [-0.05714844]\n",
      "1260 0.00042757162 [1.0239583] [-0.05446269]\n",
      "1280 0.00038833017 [1.0228323] [-0.05190319]\n",
      "1300 0.00035268549 [1.0217594] [-0.04946398]\n",
      "1320 0.00032031667 [1.020737] [-0.04713945]\n",
      "1340 0.00029091907 [1.0197623] [-0.0449243]\n",
      "1360 0.00026421473 [1.0188334] [-0.04281291]\n",
      "1380 0.0002399655 [1.0179483] [-0.04080081]\n",
      "1400 0.00021793954 [1.0171049] [-0.03888333]\n",
      "1420 0.00019793719 [1.0163009] [-0.03705596]\n",
      "1440 0.00017976959 [1.0155349] [-0.03531443]\n",
      "1460 0.000163269 [1.0148047] [-0.03365473]\n",
      "1480 0.0001482836 [1.014109] [-0.03207307]\n",
      "1500 0.0001346739 [1.013446] [-0.03056577]\n",
      "1520 0.00012231233 [1.0128139] [-0.02912926]\n",
      "1540 0.00011108428 [1.0122118] [-0.02776025]\n",
      "1560 0.00010089093 [1.0116379] [-0.02645566]\n",
      "1580 9.162969e-05 [1.011091] [-0.02521235]\n",
      "1600 8.3219806e-05 [1.0105698] [-0.02402752]\n",
      "1620 7.55821e-05 [1.0100728] [-0.02289828]\n",
      "1640 6.864449e-05 [1.0095996] [-0.02182204]\n",
      "1660 6.234271e-05 [1.0091484] [-0.02079645]\n",
      "1680 5.6619814e-05 [1.0087184] [-0.01981908]\n",
      "1700 5.14234e-05 [1.0083086] [-0.0188876]\n",
      "1720 4.6703222e-05 [1.0079182] [-0.01799994]\n",
      "1740 4.2416927e-05 [1.0075461] [-0.01715401]\n",
      "1760 3.8523995e-05 [1.0071915] [-0.01634786]\n",
      "1780 3.4988276e-05 [1.0068535] [-0.01557959]\n",
      "1800 3.1776857e-05 [1.0065314] [-0.0148474]\n",
      "1820 2.8859686e-05 [1.0062244] [-0.01414959]\n",
      "1840 2.6211257e-05 [1.0059319] [-0.01348462]\n",
      "1860 2.3805682e-05 [1.0056531] [-0.01285088]\n",
      "1880 2.1620333e-05 [1.0053874] [-0.01224693]\n",
      "1900 1.963616e-05 [1.0051342] [-0.01167136]\n",
      "1920 1.7833701e-05 [1.004893] [-0.01112282]\n",
      "1940 1.619667e-05 [1.004663] [-0.01060005]\n",
      "1960 1.4709997e-05 [1.0044439] [-0.01010189]\n",
      "1980 1.3359896e-05 [1.004235] [-0.00962717]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "# W = 1.0, b = 0 에 가깝게 나온다. \n",
    "with tf.Session() as sess:\n",
    "    # Initializes global variables in the graph.\n",
    "    # variable 사용 전에 꼭 실행시켜야 한다. \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Fit the line\n",
    "    for step in range(2000):\n",
    "        _, cost_val, W_val, b_val = sess.run([train,cost,W,b])\n",
    "        \n",
    "        if step%20 == 0:\n",
    "            print(step, cost_val, W_val, b_val)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice",
   "language": "python",
   "name": "practice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
